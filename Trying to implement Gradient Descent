def GradientDescent(X, y, alpha, n): # n is the number of features. X, y are dataframes
    theta = np.zeros(n)
    s = np.zeros(n)
    b = np.zeros(len(data))
    for i in range(len(data)):
        b[i] = np.dot(theta, X.iloc[i].T) - y[i]
        s = s + b[i]*X.iloc[i].T
        theta = theta - alpha/len(data)*s
    print('X_0 is the constant term. i.e. the value of theta_0')
    return theta
